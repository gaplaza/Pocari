{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sooonsyk/Pocari/blob/main/classification/transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjlSfhG4uRL5",
        "outputId": "ecff179d-ecbb-4cc5-981d-9310dfa8c0bf"
      },
      "id": "HjlSfhG4uRL5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **base model**\n"
      ],
      "metadata": {
        "id": "yb_fEru3uNxb"
      },
      "id": "yb_fEru3uNxb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eab73abb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eab73abb",
        "outputId": "b0ad57cb-50a6-454b-9837-54c71902ff46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 이미지 전처리 및 데이터 증강\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),  # 이미지 크기 조정\n",
        "    transforms.ToTensor(),  # 이미지를 텐서로 변환\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3319d98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3319d98",
        "outputId": "ba6cff69-91bc-48e3-f667-ef687da0228f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.9960, Train Accuracy: 25.93%, Val Loss: 2.5874, Val Accuracy: 0.00%\n",
            "Epoch [2/10], Train Loss: 1.9073, Train Accuracy: 29.63%, Val Loss: 1.8904, Val Accuracy: 30.00%\n",
            "Epoch [3/10], Train Loss: 2.3253, Train Accuracy: 37.04%, Val Loss: 1.3020, Val Accuracy: 60.00%\n",
            "Epoch [4/10], Train Loss: 1.8678, Train Accuracy: 29.63%, Val Loss: 2.2113, Val Accuracy: 60.00%\n",
            "Epoch [5/10], Train Loss: 2.2959, Train Accuracy: 25.93%, Val Loss: 1.2031, Val Accuracy: 60.00%\n",
            "Epoch [6/10], Train Loss: 1.6042, Train Accuracy: 51.85%, Val Loss: 1.2877, Val Accuracy: 70.00%\n",
            "Epoch [7/10], Train Loss: 1.8625, Train Accuracy: 40.74%, Val Loss: 2.6208, Val Accuracy: 10.00%\n",
            "Epoch [8/10], Train Loss: 1.1540, Train Accuracy: 51.85%, Val Loss: 1.4108, Val Accuracy: 40.00%\n",
            "Epoch [9/10], Train Loss: 1.1536, Train Accuracy: 66.67%, Val Loss: 1.3695, Val Accuracy: 40.00%\n",
            "Epoch [10/10], Train Loss: 0.9265, Train Accuracy: 70.37%, Val Loss: 1.9548, Val Accuracy: 20.00%\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models  #ResNet 사용\n",
        "\n",
        "# 전이 학습에 사용할 사전 학습된 ResNet 모델 로드\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 마지막 fully connected layer를 새로운 출력에 맞게 수정\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(dataset.classes))  # dataset.classes는 이미지 데이터셋의 클래스 수\n",
        "\n",
        "# GPU를 사용할 수 있는 경우 GPU로 모델 이동\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100. * correct / total\n",
        "\n",
        "        # 검증 데이터셋에 대한 성능 측정\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = 100. * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# 학습 및 평가 실행\n",
        "train(model, criterion, optimizer, train_loader, val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d352d24d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d352d24d",
        "outputId": "a1d5ddfe-6786-453f-8a20-b273df455c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 10.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [2, 2, 0, 0, 2, 2, 3, 0, 2, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **white balance 추가**\n"
      ],
      "metadata": {
        "id": "iAGA225uuaOL"
      },
      "id": "iAGA225uuaOL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "783f356d-7b95-4d8f-e19b-2366f7a3fa67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA7rFPtKuaOM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import img_as_ubyte                        #이미지 처리 - white balance 에 활용\n",
        "from PIL import Image\n",
        "\n",
        "def white_patch(image, percentile=100):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : 입력으로 받는 이미지는 RGB 채널을 각각 가지는 (height, width, channels) 3차원 numpy 배열\n",
        "    percentile : 채널 값의 보정값으로 사용하고자 하는 값을 지정하기 위한 비율, 기본값은 100으로 최대값을 사용\n",
        "    \"\"\"\n",
        "\n",
        "    image = np.array(image)\n",
        "\n",
        "    white_patch_image = img_as_ubyte(\n",
        "        (image * 1.0 / np.percentile(image,\n",
        "                                     percentile,\n",
        "                                     axis=(0, 1))).clip(0, 1))\n",
        "    return Image.fromarray(white_patch_image)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.Lambda(lambda x: white_patch(x, percentile=85)),  # 전처리 함수 적용\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ],
      "id": "CA7rFPtKuaOM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "e002029d-7638-44d9-f5ef-91f1c09f35df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6tG0cOpuaOM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.9344, Train Accuracy: 25.93%, Val Loss: 1.6765, Val Accuracy: 10.00%\n",
            "Epoch [2/10], Train Loss: 2.1372, Train Accuracy: 11.11%, Val Loss: 1.8797, Val Accuracy: 60.00%\n",
            "Epoch [3/10], Train Loss: 1.4425, Train Accuracy: 40.74%, Val Loss: 1.9368, Val Accuracy: 30.00%\n",
            "Epoch [4/10], Train Loss: 2.2977, Train Accuracy: 44.44%, Val Loss: 2.4211, Val Accuracy: 10.00%\n",
            "Epoch [5/10], Train Loss: 1.8399, Train Accuracy: 37.04%, Val Loss: 1.9213, Val Accuracy: 30.00%\n",
            "Epoch [6/10], Train Loss: 1.6175, Train Accuracy: 44.44%, Val Loss: 1.6453, Val Accuracy: 40.00%\n",
            "Epoch [7/10], Train Loss: 1.6030, Train Accuracy: 48.15%, Val Loss: 2.7516, Val Accuracy: 0.00%\n",
            "Epoch [8/10], Train Loss: 2.1997, Train Accuracy: 25.93%, Val Loss: 2.6642, Val Accuracy: 20.00%\n",
            "Epoch [9/10], Train Loss: 1.6983, Train Accuracy: 44.44%, Val Loss: 1.7541, Val Accuracy: 30.00%\n",
            "Epoch [10/10], Train Loss: 1.0680, Train Accuracy: 59.26%, Val Loss: 2.6596, Val Accuracy: 10.00%\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models  #ResNet 사용\n",
        "\n",
        "# 전이 학습에 사용할 사전 학습된 ResNet 모델 로드\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 마지막 fully connected layer를 새로운 출력에 맞게 수정\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(dataset.classes))  # dataset.classes는 이미지 데이터셋의 클래스 수\n",
        "\n",
        "# GPU를 사용할 수 있는 경우 GPU로 모델 이동\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100. * correct / total\n",
        "\n",
        "        # 검증 데이터셋에 대한 성능 측정\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = 100. * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# 학습 및 평가 실행\n",
        "train(model, criterion, optimizer, train_loader, val_loader)\n"
      ],
      "id": "i6tG0cOpuaOM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "6db49af2-4c4e-443c-96d5-b7eada90952b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCNI5pcvuaOM"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 10.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [2, 3, 3, 0, 2, 1, 0, 2, 0, 2]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "id": "zCNI5pcvuaOM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **이미지 증강 추가**\n"
      ],
      "metadata": {
        "id": "RK58X5wlupb4"
      },
      "id": "RK58X5wlupb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "7149a725-d2bb-4a73-acd3-ced4837ae380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCkRY1ltupb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import img_as_ubyte                        #이미지 처리 - white balance 에 활용\n",
        "from PIL import Image\n",
        "\n",
        "def white_patch(image, percentile=100):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : 입력으로 받는 이미지는 RGB 채널을 각각 가지는 (height, width, channels) 3차원 numpy 배열\n",
        "    percentile : 채널 값의 보정값으로 사용하고자 하는 값을 지정하기 위한 비율, 기본값은 100으로 최대값을 사용\n",
        "    \"\"\"\n",
        "\n",
        "    image = np.array(image)\n",
        "\n",
        "    white_patch_image = img_as_ubyte(\n",
        "        (image * 1.0 / np.percentile(image,\n",
        "                                     percentile,\n",
        "                                     axis=(0, 1))).clip(0, 1))\n",
        "    return Image.fromarray(white_patch_image)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.Lambda(lambda x: white_patch(x, percentile=85)),  # 전처리 함수 적용\n",
        "    transforms.RandomHorizontalFlip(),  # 랜덤으로 이미지를 수평으로 뒤집기\n",
        "    transforms.RandomVerticalFlip(p=0.5), # 랜덤으로 이미지를 수직으로 뒤집기\n",
        "    transforms.RandomRotation(degrees=(-10, 10)), # 랜덤으로 이미지 회전\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ],
      "id": "vCkRY1ltupb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "5607d6e4-0738-4dbb-fcd2-382ac2138571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5rG7TE3upb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 2.6882, Train Accuracy: 22.22%, Val Loss: 1.5937, Val Accuracy: 60.00%\n",
            "Epoch [2/10], Train Loss: 2.5051, Train Accuracy: 18.52%, Val Loss: 1.2505, Val Accuracy: 30.00%\n",
            "Epoch [3/10], Train Loss: 3.2872, Train Accuracy: 11.11%, Val Loss: 1.5582, Val Accuracy: 30.00%\n",
            "Epoch [4/10], Train Loss: 2.2890, Train Accuracy: 25.93%, Val Loss: 3.0036, Val Accuracy: 0.00%\n",
            "Epoch [5/10], Train Loss: 3.4100, Train Accuracy: 22.22%, Val Loss: 2.8324, Val Accuracy: 0.00%\n",
            "Epoch [6/10], Train Loss: 2.6505, Train Accuracy: 40.74%, Val Loss: 2.8419, Val Accuracy: 0.00%\n",
            "Epoch [7/10], Train Loss: 2.2295, Train Accuracy: 40.74%, Val Loss: 2.3261, Val Accuracy: 10.00%\n",
            "Epoch [8/10], Train Loss: 1.7492, Train Accuracy: 37.04%, Val Loss: 0.9496, Val Accuracy: 60.00%\n",
            "Epoch [9/10], Train Loss: 1.9807, Train Accuracy: 29.63%, Val Loss: 1.4008, Val Accuracy: 40.00%\n",
            "Epoch [10/10], Train Loss: 2.2895, Train Accuracy: 11.11%, Val Loss: 1.0019, Val Accuracy: 60.00%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# 전이 학습에 사용할 사전 학습된 ResNet 모델 로드\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 마지막 fully connected layer를 새로운 출력에 맞게 수정\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, len(dataset.classes))  # dataset.classes는 이미지 데이터셋의 클래스 수\n",
        "\n",
        "# GPU를 사용할 수 있는 경우 GPU로 모델 이동\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_accuracy = 100. * correct / total\n",
        "\n",
        "        # 검증 데이터셋에 대한 성능 측정\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "        val_accuracy = 100. * correct / total\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
        "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "# 학습 및 평가 실행\n",
        "train(model, criterion, optimizer, train_loader, val_loader)\n"
      ],
      "id": "W5rG7TE3upb6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "6a47b505-c479-4c80-eaea-9ea0b8186a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6tgS_dfupb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 20.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [3, 3, 4, 3, 4, 3, 4, 4, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "id": "k6tgS_dfupb6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}