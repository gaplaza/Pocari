{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sooonsyk/Pocari/blob/main/classification/stoolnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPi35W98tmrn",
        "outputId": "0c0460d3-b29e-4d1f-d19b-66ae7b05ae98"
      },
      "id": "gPi35W98tmrn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **base model**"
      ],
      "metadata": {
        "id": "ZkdKIV71swe7"
      },
      "id": "ZkdKIV71swe7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da4d5dd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da4d5dd9",
        "outputId": "b8de96df-26c7-4aa1-cae4-82459abf29a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os                                               #파일 접근\n",
        "import torch                                            #신경망 사용\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim                             #최적화 알고리즘 제공\n",
        "from torchvision import datasets, transforms            #데이터셋 사용, 이미지 데이터 전처리\n",
        "from torch.utils.data import DataLoader                 #데이터 미니배치로 나누어서 로드\n",
        "from sklearn.model_selection import train_test_split    #학습, 검증, 테스트 데이터 분리\n",
        "\n",
        "\n",
        "# 이미지 전처리 및 데이터 증강\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),        # 이미지 크기 조정\n",
        "    transforms.ToTensor(),                # 이미지를 텐서로 변환\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e1b9af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27e1b9af",
        "outputId": "f61e59f8-6d69-4f2c-9030-2213614e9d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StoolNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=160000, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=5, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class StoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StoolNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(50 * 50 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, 5)  # 클래스 수가 5개이므로 출력 크기는 5로 설정\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        # 3D 텐서 1D 텐서로 변환\n",
        "        x = x.view(-1, 50 * 50 * 64)\n",
        "        # Fully connected layers with ReLU activation and dropout\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        # 결과 출력\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# StoolNet 모델 인스턴스 생성\n",
        "model = StoolNet()\n",
        "\n",
        "# 모델 구조 확인\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f7b101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27f7b101",
        "outputId": "9aa1b28f-6235-4c53-aba8-3fd3769ccda5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.6429, Val Loss: 1.4111, Val Acc: 0.6000\n",
            "Epoch [2/10], Loss: 1.2948, Val Loss: 1.7223, Val Acc: 0.3000\n",
            "Epoch [3/10], Loss: 0.9778, Val Loss: 2.5036, Val Acc: 0.6000\n",
            "Epoch [4/10], Loss: 0.7180, Val Loss: 2.4721, Val Acc: 0.3000\n",
            "Epoch [5/10], Loss: 0.7957, Val Loss: 2.3230, Val Acc: 0.5000\n",
            "Epoch [6/10], Loss: 1.0851, Val Loss: 1.5753, Val Acc: 0.5000\n",
            "Epoch [7/10], Loss: 0.9966, Val Loss: 2.4621, Val Acc: 0.2000\n",
            "Epoch [8/10], Loss: 0.4746, Val Loss: 6.0247, Val Acc: 0.4000\n",
            "Epoch [9/10], Loss: 0.3013, Val Loss: 5.8727, Val Acc: 0.3000\n",
            "Epoch [10/10], Loss: 1.2166, Val Loss: 2.6068, Val Acc: 0.7000\n"
          ]
        }
      ],
      "source": [
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        # 학습 단계\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # 결과 출력\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# StoolNet 모델 학습\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae09d18c",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae09d18c",
        "outputId": "6225a073-5c3a-4c2f-eda1-9fd36e162a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 60.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [3, 4, 3, 4, 2, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca16eac2",
      "metadata": {
        "id": "ca16eac2"
      },
      "source": [
        "### **White balance 추가**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1659527c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1659527c",
        "outputId": "0384c1d6-6b13-4f98-bbd1-093dad9dc262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import img_as_ubyte\n",
        "from PIL import Image\n",
        "\n",
        "def white_patch(image, percentile=100):\n",
        "\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : 입력으로 받는 이미지는 RGB 채널을 각각 가지는 (height, width, channels) 3차원 numpy 배열\n",
        "    percentile : 채널 값의 보정값으로 사용하고자 하는 값을 지정하기 위한 비율, 기본값은 100으로 최대값을 사용\n",
        "    \"\"\"\n",
        "\n",
        "    image = np.array(image)\n",
        "\n",
        "    white_patch_image = img_as_ubyte(\n",
        "        (image * 1.0 / np.percentile(image,\n",
        "                                     percentile,\n",
        "                                     axis=(0, 1))).clip(0, 1))\n",
        "    return Image.fromarray(white_patch_image)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.Lambda(lambda x: white_patch(x, percentile=85)),  # 전처리 함수 적용\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e7e509a",
      "metadata": {
        "id": "6e7e509a"
      },
      "outputs": [],
      "source": [
        "class StoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StoolNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(50 * 50 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, 5)  # 클래스 수가 5개이므로 출력 크기는 5로 설정\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        # 3D 텐서 1D 텐서로 변환\n",
        "        x = x.view(-1, 50 * 50 * 64)\n",
        "        # Fully connected layers with ReLU activation and dropout\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        # 결과 출력\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb5bd6bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb5bd6bc",
        "outputId": "4734834c-d1f9-44f9-a143-a233c00ebb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6078, Val Loss: 8.8295, Val Acc: 0.2000\n",
            "Epoch [2/10], Loss: 0.2956, Val Loss: 6.4987, Val Acc: 0.4000\n",
            "Epoch [3/10], Loss: 0.9034, Val Loss: 4.0934, Val Acc: 0.6000\n",
            "Epoch [4/10], Loss: 4.9964, Val Loss: 2.5359, Val Acc: 0.0000\n",
            "Epoch [5/10], Loss: 1.6561, Val Loss: 2.1224, Val Acc: 0.2000\n",
            "Epoch [6/10], Loss: 6.1548, Val Loss: 1.8241, Val Acc: 0.1000\n",
            "Epoch [7/10], Loss: 1.5156, Val Loss: 1.4686, Val Acc: 0.6000\n",
            "Epoch [8/10], Loss: 1.4155, Val Loss: 1.6988, Val Acc: 0.3000\n",
            "Epoch [9/10], Loss: 1.7199, Val Loss: 1.3363, Val Acc: 0.6000\n",
            "Epoch [10/10], Loss: 0.9629, Val Loss: 2.2830, Val Acc: 0.6000\n"
          ]
        }
      ],
      "source": [
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        # 학습 단계\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # 결과 출력\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# StoolNet 모델 학습\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290c12fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290c12fe",
        "outputId": "2b8a9dcd-85ec-4204-fbc2-a4a49ba8313e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 40.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [3, 3, 3, 3, 2, 3, 3, 3, 3, 3]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc8tH_DXs13h"
      },
      "source": [
        "### **이미지 증강 추가**"
      ],
      "id": "qc8tH_DXs13h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "55b973d2-8121-474a-c837-75d460ab41d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-91OySPs13h"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['blood', 'diarrhea', 'green', 'normal', 'white']\n",
            "Number of training samples: 27\n",
            "Number of validation samples: 10\n",
            "Number of test samples: 10\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import img_as_ubyte\n",
        "from PIL import Image\n",
        "\n",
        "def white_patch(image, percentile=100):\n",
        "    \"\"\"\n",
        "    Returns a plot comparison of original and corrected/white balanced image\n",
        "    using the White Patch algorithm.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image : numpy array\n",
        "            Image to process using white patch algorithm\n",
        "    percentile : integer, optional\n",
        "                  Percentile value to consider as channel maximum\n",
        "    \"\"\"\n",
        "    image = np.array(image)\n",
        "\n",
        "    white_patch_image = img_as_ubyte(\n",
        "        (image * 1.0 / np.percentile(image,\n",
        "                                     percentile,\n",
        "                                     axis=(0, 1))).clip(0, 1))\n",
        "    return Image.fromarray(white_patch_image)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((200, 200)),\n",
        "    transforms.Lambda(lambda x: white_patch(x, percentile=85)),  # 전처리 함수 적용\n",
        "    transforms.RandomHorizontalFlip(),  # 랜덤으로 이미지를 수평으로 뒤집기\n",
        "    transforms.RandomVerticalFlip(p=0.5), # 랜덤으로 이미지를 수직으로 뒤집기\n",
        "    transforms.RandomRotation(degrees=(-10, 10)), # 랜덤으로 이미지 회전\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # 정규화\n",
        "])\n",
        "\n",
        "# 이미지 데이터셋 로드\n",
        "dataset = datasets.ImageFolder(root='/content/drive/MyDrive/images_0601', transform=transform)\n",
        "\n",
        "# 데이터셋을 학습, 검증, 테스트로 분할\n",
        "train_val_indices, test_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=42)\n",
        "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # train 60%, val 20%, test 20%\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
        "\n",
        "# DataLoader 생성 - data 수 적어서 batch 지정 안 함\n",
        "train_loader = DataLoader(dataset=train_dataset, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_dataset, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, shuffle=False)\n",
        "\n",
        "# 데이터셋 클래스 확인\n",
        "print(\"Classes:\", dataset.classes)\n",
        "print(\"Number of training samples:\", len(train_dataset))\n",
        "print(\"Number of validation samples:\", len(val_dataset))\n",
        "print(\"Number of test samples:\", len(test_dataset))"
      ],
      "id": "b-91OySPs13h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5MTnT3_s13i"
      },
      "outputs": [],
      "source": [
        "class StoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StoolNet, self).__init__()\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
        "        # Max pooling layers\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(50 * 50 * 64, 512)\n",
        "        self.fc2 = nn.Linear(512, 5)  # 클래스 수가 5개이므로 출력 크기는 5로 설정\n",
        "        # Dropout layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional layers with ReLU activation and max pooling\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        # 3D 텐서 1D 텐서로 변환\n",
        "        x = x.view(-1, 50 * 50 * 64)\n",
        "        # Fully connected layers with ReLU activation and dropout\n",
        "        x = self.dropout(torch.relu(self.fc1(x)))\n",
        "        # 결과 출력\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "id": "E5MTnT3_s13i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "03c1bf39-8546-4159-b313-bc6f97cb6a39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlDBXC-5s13j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.7074, Val Loss: 1.1078, Val Acc: 0.6000\n",
            "Epoch [2/10], Loss: 1.2558, Val Loss: 0.9307, Val Acc: 0.7000\n",
            "Epoch [3/10], Loss: 1.2411, Val Loss: 1.0446, Val Acc: 0.7000\n",
            "Epoch [4/10], Loss: 1.1634, Val Loss: 1.1637, Val Acc: 0.7000\n",
            "Epoch [5/10], Loss: 1.1648, Val Loss: 0.9652, Val Acc: 0.7000\n",
            "Epoch [6/10], Loss: 1.1105, Val Loss: 1.2308, Val Acc: 0.5000\n",
            "Epoch [7/10], Loss: 1.0454, Val Loss: 1.4434, Val Acc: 0.3000\n",
            "Epoch [8/10], Loss: 1.0926, Val Loss: 1.3187, Val Acc: 0.6000\n",
            "Epoch [9/10], Loss: 0.8042, Val Loss: 1.5268, Val Acc: 0.6000\n",
            "Epoch [10/10], Loss: 0.6870, Val Loss: 1.5043, Val Acc: 0.5000\n"
          ]
        }
      ],
      "source": [
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 학습 함수 정의\n",
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        # 학습 단계\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # 결과 출력\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "# StoolNet 모델 학습\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
      ],
      "id": "LlDBXC-5s13j"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRrnshE7s13j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f86071-a594-41d6-aed0-63fa440cfd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 70.00%\n",
            "True Labels: [3, 4, 3, 4, 3, 4, 2, 3, 1, 3]\n",
            "Predicted Labels: [3, 4, 3, 4, 3, 4, 2, 2, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "# 테스트 데이터셋을 사용하여 모델 평가\n",
        "def test(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # 예측된 레이블과 실제 레이블 저장\n",
        "            predicted_labels.extend(predicted.tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct / total\n",
        "    print(f'Test Accuracy: {test_accuracy:.2%}')\n",
        "    return true_labels, predicted_labels\n",
        "\n",
        "true_labels, predicted_labels = test(model, test_loader)\n",
        "\n",
        "# 실제 레이블과 예측된 레이블 출력\n",
        "print(\"True Labels:\", true_labels)\n",
        "print(\"Predicted Labels:\", predicted_labels)\n"
      ],
      "id": "qRrnshE7s13j"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}